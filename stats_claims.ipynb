{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def ouvrir_json(chemin):\n",
    "  f = open(chemin, encoding=\"utf-8\")\n",
    "  toto = json.load(f)\n",
    "  f.close()\n",
    "  return toto \n",
    "\n",
    "def ecrire_json(chemin, contenu):\n",
    "  w = open(chemin, \"w\", encoding=\"utf-8\")\n",
    "  w.write(json.dumps(contenu, indent=2, ensure_ascii=False))\n",
    "  w.close()\n",
    "\n",
    "def trier_dic(dic):\n",
    "    L = [[effectif,doc] for doc,effectif in dic.items()]\n",
    "    L_sorted = sorted(L, reverse=True)\n",
    "    return [[doc,effectif] for effectif,doc in L_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listes à partir de l'état de l'art\n",
    "verbes = [\"find\",\"can\", \"could\", \"may\", \"might\", \"must\", \"should\", \"claim\", \"admit\", \"discover\", \"suggest\", \"predict\",\n",
    "        \"prove\", \"show\", \"support\", \"explain\", \"infer\", \"conclude\", \"demonstrate\", \"lead\", \"succeed\", \"intend\", \"indicate\",\n",
    "          \"assume\", \"appear\", \"seem\",\"favor\",\"think\",\"believe\",\"analyze\",\"examine\", \"report\",\"dare\", \"point out\", \"note\",\n",
    "         \"assert\",\"state\",\"declare\",\"remark\",\"comment\",\"observe\",\"reveal\",\"disclose\",\"confirm\",\"convince\"]\n",
    "adv = [\"certainly\",\"necessarily\", \"apparently\", \"probably\",\"likely\", \"possibly\", \"presumably\", \"seemingly\", \"firmly\", \n",
    "       \"perhaps\", \"obviously\", \"definitely\", \"indeed\", \"presumably\", \"surely\",\"undoubtedly\", \"evidently\",\"significantly\",\n",
    "      \"remarkably\",\"admittedly\",\"assuredly\",\"incontestably\",\"indisputably\", \"indubitably\", \"unarguably\", \"undeniably\", \n",
    "       \"undoubtedly\", \"unquestionably\", \"clearly\", \"greatly\",\"manifestly\"]\n",
    "adj = [\"certain\", \"necessary\", \"sure\", \"apparent\", \"probable\", \"presumed\", \"hypothetic\", \"significant\", \"able\", \"evident\",\n",
    "    \"clear\", \"possible\",\"potential\",\"amazingly\", \"greatly\", \"perfectly\", \"unbelievably\",\"crucial\",\"best\",\"most\",\n",
    "       \"unprecedented\"]\n",
    "noms = [\"evidence\", \"proof\", \"guarantee\",\"proposal\",\"likelihood\",\"allegation\"]\n",
    "indices = verbes+adv+adj+noms\n",
    "indices_nonV = adv+adj+noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans la partie abstracts il y a 33804 claims trouvés à partir des indices verbaux seulement\n",
      "\tIl y a 59411 indices au total dans les claims extraits avec seulement les verbes, dont 53168 verbes et 6243 indices non verbaux.\n",
      "\t\tSoit : 10.51 % d'indices non verbaux et 89.49 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  6.79 % d'adjectifs parmi tous les indices et 64.62 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 2.61 % d'adverbes parmi tous les indices et 24.8 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 1.27 % de noms parmi tous les indices et 12.13 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n",
      "Dans la partie intros il y a 45997 claims trouvés à partir des indices verbaux seulement\n",
      "\tIl y a 137980 indices au total dans les claims extraits avec seulement les verbes, dont 123573 verbes et 14407 indices non verbaux.\n",
      "\t\tSoit : 10.44 % d'indices non verbaux et 89.56 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  7.05 % d'adjectifs parmi tous les indices et 67.5 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 2.48 % d'adverbes parmi tous les indices et 23.76 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 1.07 % de noms parmi tous les indices et 10.26 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n",
      "Dans la partie corps il y a 371204 claims trouvés à partir des indices verbaux seulement\n",
      "\tIl y a 762222 indices au total dans les claims extraits avec seulement les verbes, dont 686541 verbes et 75681 indices non verbaux.\n",
      "\t\tSoit : 9.93 % d'indices non verbaux et 90.07 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  6.73 % d'adjectifs parmi tous les indices et 67.8 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 2.22 % d'adverbes parmi tous les indices et 22.41 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 1.07 % de noms parmi tous les indices et 10.81 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n",
      "Dans la partie ccl il y a 62910 claims trouvés à partir des indices verbaux seulement\n",
      "\tIl y a 869807 indices au total dans les claims extraits avec seulement les verbes, dont 782887 verbes et 86920 indices non verbaux.\n",
      "\t\tSoit : 9.99 % d'indices non verbaux et 90.01 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  6.76 % d'adjectifs parmi tous les indices et 67.61 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 2.26 % d'adverbes parmi tous les indices et 22.62 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 1.08 % de noms parmi tous les indices et 10.79 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Regarder le nombre d'indices non-verbaux contenus dans les claims extraits seulement avec indices verbaux,\n",
    "comparer avec le nombre d'indices totaux dans tous les claims,\n",
    "faire stats par catégorie sur claims totaux et claims extraits avec seulement indices verbaux\"\"\"\n",
    "\n",
    "partie = [\"abstracts\",\"intros\",\"corps\",\"ccl\"]\n",
    "nb_indicesnonV = 0\n",
    "nb_V = 0\n",
    "nb_adj = 0\n",
    "nb_adv = 0\n",
    "nb_n = 0\n",
    "\n",
    "for p in partie:\n",
    "    claims = ouvrir_json(\"claims_decoupes_%s_v06-2.json\"%p) #liste de dictionnaires article:claim\n",
    "    print(\"Dans la partie\", p, \"il y a\", len(claims), \"claims trouvés à partir des indices verbaux seulement\")\n",
    "    for dico in claims:\n",
    "        for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices_nonV:\n",
    "                    nb_indicesnonV +=1\n",
    "                if word in verbes:\n",
    "                    nb_V += 1\n",
    "                if word in adj : \n",
    "                    nb_adj +=1\n",
    "                if word in adv:\n",
    "                    nb_adv +=1\n",
    "                if word in noms:\n",
    "                    nb_n +=1\n",
    "    total = nb_indicesnonV + nb_V\n",
    "    print(\"\\tIl y a\", total, \"indices au total dans les claims extraits avec seulement les verbes, dont\", nb_V, \"verbes et\", nb_indicesnonV, \"indices non verbaux.\")\n",
    "    print(\"\\t\\tSoit :\", round(nb_indicesnonV/total*100,2), \"% d'indices non verbaux et\", round(nb_V/total*100,2), \"d'indices verbaux.\")\n",
    "    print(\"\\t\\tDétails des indices non verbaux : \", round(nb_adj/total*100,2), \"% d'adjectifs parmi tous les indices et\", round(nb_adj/nb_indicesnonV*100, 2), \"% d'adjectifs parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_adv/total*100,2), \"% d'adverbes parmi tous les indices et\", round(nb_adv/nb_indicesnonV*100, 2), \"% d'adverbes parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_n/total*100,2), \"% de noms parmi tous les indices et\", round(nb_n/nb_indicesnonV*100, 2), \"% de noms parmi les indices non verbaux\")\n",
    "    print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513915\n",
      "333248\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Regarder s'il y a doublons\"\"\"\n",
    "\n",
    "partie = [\"abstracts\",\"intros\",\"corps\",\"ccl\"]\n",
    "liste_c = []\n",
    "\n",
    "for p in partie:\n",
    "    claims = ouvrir_json(\"claims_decoupes_%s_v06-2.json\"%p) #liste de dictionnaires article:claim\n",
    "    for dico in claims:\n",
    "        for article, claim in dico.items():\n",
    "            liste_c.append(claim)\n",
    "            \n",
    "print(len(liste_c))\n",
    "print(len(set(liste_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans la partie abstracts il y a 43834 claims trouvés à partir de tous les types d'indices\n",
      "\tIl y a 77778 indices au total dans les claims extraits avec tous les indices, dont 59411 verbes et 18367 indices non verbaux.\n",
      "\t\tSoit : 23.61 % d'indices non verbaux et 76.39 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  16.15 % d'adjectifs parmi tous les indices et 68.41 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 4.74 % d'adverbes parmi tous les indices et 20.08 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 2.99 % de noms parmi tous les indices et 12.67 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n",
      "Dans la partie intros il y a 61691 claims trouvés à partir de tous les types d'indices\n",
      "\tIl y a 183587 indices au total dans les claims extraits avec tous les indices, dont 137980 verbes et 45607 indices non verbaux.\n",
      "\t\tSoit : 24.84 % d'indices non verbaux et 75.16 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  17.68 % d'adjectifs parmi tous les indices et 71.16 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 5.0 % d'adverbes parmi tous les indices et 20.13 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 2.46 % de noms parmi tous les indices et 9.9 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n",
      "Dans la partie corps il y a 491710 claims trouvés à partir de tous les types d'indices\n",
      "\tIl y a 1024509 indices au total dans les claims extraits avec tous les indices, dont 762222 verbes et 262287 indices non verbaux.\n",
      "\t\tSoit : 25.6 % d'indices non verbaux et 74.4 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  18.14 % d'adjectifs parmi tous les indices et 70.87 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 4.99 % d'adverbes parmi tous les indices et 19.48 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 2.67 % de noms parmi tous les indices et 10.41 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n",
      "Dans la partie ccl il y a 82007 claims trouvés à partir de tous les types d'indices\n",
      "\tIl y a 1167946 indices au total dans les claims extraits avec tous les indices, dont 869807 verbes et 298139 indices non verbaux.\n",
      "\t\tSoit : 25.53 % d'indices non verbaux et 74.47 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  18.05 % d'adjectifs parmi tous les indices et 70.72 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 5.03 % d'adverbes parmi tous les indices et 19.72 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 2.64 % de noms parmi tous les indices et 10.33 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Même chose mais pour comparer avec claims extraits avec tous indices\"\"\"\n",
    "\n",
    "partie = [\"abstracts\",\"intros\",\"corps\",\"ccl\"]\n",
    "nb_indicesnonV = 0\n",
    "nb_V = 0\n",
    "nb_adj = 0\n",
    "nb_adv = 0\n",
    "nb_n = 0\n",
    "\n",
    "for p in partie:\n",
    "    claims = ouvrir_json(\"claims_decoupes_%s_v06-2.json\"%p) #liste de dictionnaires article:claim\n",
    "    print(\"Dans la partie\", p, \"il y a\", len(claims), \"claims trouvés à partir des indices verbaux seulement\")\n",
    "    for dico in claims:\n",
    "        for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices_nonV:\n",
    "                    nb_indicesnonV +=1\n",
    "                if word in verbes:\n",
    "                    nb_V += 1\n",
    "                if word in adj : \n",
    "                    nb_adj +=1\n",
    "                if word in adv:\n",
    "                    nb_adv +=1\n",
    "                if word in noms:\n",
    "                    nb_n +=1\n",
    "    total = nb_indicesnonV + nb_V\n",
    "    print(\"\\tIl y a\", total, \"indices au total dans les claims extraits avec seulement les verbes, dont\", nb_V, \"verbes et\", nb_indicesnonV, \"indices non verbaux.\")\n",
    "    print(\"\\t\\tSoit :\", round(nb_indicesnonV/total*100,2), \"% d'indices non verbaux et\", round(nb_V/total*100,2), \"d'indices verbaux.\")\n",
    "    print(\"\\t\\tDétails des indices non verbaux : \", round(nb_adj/total*100,2), \"% d'adjectifs parmi tous les indices et\", round(nb_adj/nb_indicesnonV*100, 2), \"% d'adjectifs parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_adv/total*100,2), \"% d'adverbes parmi tous les indices et\", round(nb_adv/nb_indicesnonV*100, 2), \"% d'adverbes parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_n/total*100,2), \"% de noms parmi tous les indices et\", round(nb_n/nb_indicesnonV*100, 2), \"% de noms parmi les indices non verbaux\")\n",
    "    print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstracts\n",
      "Avec les indices verbaux seulement on détecte 33804 claims alors qu'avec tous les indices on en trouve 43834\n",
      "Donc avec seulement les indices verbaux on en détecte 77.12 % (si on laisse tomber le bruit entraîné par les indices non verbaux)\n",
      "********************************************************************************\n",
      "intros\n",
      "Avec les indices verbaux seulement on détecte 45997 claims alors qu'avec tous les indices on en trouve 61691\n",
      "Donc avec seulement les indices verbaux on en détecte 74.56 % (si on laisse tomber le bruit entraîné par les indices non verbaux)\n",
      "********************************************************************************\n",
      "corps\n",
      "Avec les indices verbaux seulement on détecte 371204 claims alors qu'avec tous les indices on en trouve 491710\n",
      "Donc avec seulement les indices verbaux on en détecte 75.49 % (si on laisse tomber le bruit entraîné par les indices non verbaux)\n",
      "********************************************************************************\n",
      "ccl\n",
      "Avec les indices verbaux seulement on détecte 62910 claims alors qu'avec tous les indices on en trouve 82007\n",
      "Donc avec seulement les indices verbaux on en détecte 76.71 % (si on laisse tomber le bruit entraîné par les indices non verbaux)\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "total_claims_v = []\n",
    "total_claims = []\n",
    "for p in partie:\n",
    "    claims_v = ouvrir_json(\"claims_decoupes_%s_v06-2.json\"%p)\n",
    "    claims = ouvrir_json(\"claims_decoupes_%s_tousindices.json\"%p) \n",
    "    total_claims_v+=claims_v\n",
    "    total_claims+=claims\n",
    "    print(p)\n",
    "    print(\"Avec les indices verbaux seulement on détecte\", len(claims_v), \"claims alors qu'avec tous les indices on en trouve\", len(claims))\n",
    "    print(\"Donc avec seulement les indices verbaux on en détecte\", round(len(claims_v)/len(claims)*100,2), \"% (si on laisse tomber le bruit entraîné par les indices non verbaux)\")\n",
    "    print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TOUTES PARTIES CONFONDUES\n",
      "Avec les indices verbaux seulement on détecte 513915 claims alors qu'avec tous les indices on en trouve 679242\n",
      "Donc avec seulement les indices verbaux on en détecte 75.66 % (si on laisse tomber le bruit entraîné par les indices non verbaux)\n",
      "\n",
      " ********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"TOTAL TOUTES PARTIES CONFONDUES\")\n",
    "print(\"Avec les indices verbaux seulement on détecte\", len(total_claims_v), \"claims alors qu'avec tous les indices on en trouve\", len(total_claims))\n",
    "print(\"Donc avec seulement les indices verbaux on en détecte\", round(len(total_claims_v)/len(total_claims)*100,2), \"% (si on laisse tomber le bruit entraîné par les indices non verbaux)\")\n",
    "print(\"\\n\",\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POUR CLAIMS EXTRAITS AVEC TOUS LES INDICES, TOUTES PARTIES CONFONDUES\n",
      "\tIl y a 1167946 indices au total dans les claims extraits avec seulement les verbes, dont 869807 verbes et 298139 indices non verbaux.\n",
      "\t\tSoit : 25.53 % d'indices non verbaux et 74.47 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  18.05 % d'adjectifs parmi tous les indices et 70.72 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 5.03 % d'adverbes parmi tous les indices et 19.72 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 2.64 % de noms parmi tous les indices et 10.33 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n",
      "POUR CLAIMS EXTRAITS AVEC SEULEMENT AVEC VERBES, TOUTES PARTIES CONFONDUES\n",
      "\tIl y a 869807 indices au total dans les claims extraits avec seulement les verbes, dont 782887 verbes et 86920 indices non verbaux.\n",
      "\t\tSoit : 9.99 % d'indices non verbaux et 90.01 d'indices verbaux.\n",
      "\t\tDétails des indices non verbaux :  6.76 % d'adjectifs parmi tous les indices et 67.61 % d'adjectifs parmi les indices non verbaux\n",
      "\t\t 2.26 % d'adverbes parmi tous les indices et 22.62 % d'adverbes parmi les indices non verbaux\n",
      "\t\t 1.08 % de noms parmi tous les indices et 10.79 % de noms parmi les indices non verbaux\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"Refaire sur total, toutes parties confondues\"\"\"\n",
    "\n",
    "    print(\"POUR CLAIMS EXTRAITS AVEC TOUS LES INDICES, TOUTES PARTIES CONFONDUES\")\n",
    "    nb_indicesnonV = 0\n",
    "    nb_V = 0\n",
    "    nb_adj = 0\n",
    "    nb_adv = 0\n",
    "    nb_n = 0\n",
    "\n",
    "    for dico in total_claims:\n",
    "        for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices_nonV:\n",
    "                    nb_indicesnonV +=1\n",
    "                if word in verbes:\n",
    "                    nb_V += 1\n",
    "                if word in adj : \n",
    "                    nb_adj +=1\n",
    "                if word in adv:\n",
    "                    nb_adv +=1\n",
    "                if word in noms:\n",
    "                    nb_n +=1\n",
    "    total = nb_indicesnonV + nb_V\n",
    "    print(\"\\tIl y a\", total, \"indices au total dans les claims extraits avec seulement les verbes, dont\", nb_V, \"verbes et\", nb_indicesnonV, \"indices non verbaux.\")\n",
    "    print(\"\\t\\tSoit :\", round(nb_indicesnonV/total*100,2), \"% d'indices non verbaux et\", round(nb_V/total*100,2), \"d'indices verbaux.\")\n",
    "    print(\"\\t\\tDétails des indices non verbaux : \", round(nb_adj/total*100,2), \"% d'adjectifs parmi tous les indices et\", round(nb_adj/nb_indicesnonV*100, 2), \"% d'adjectifs parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_adv/total*100,2), \"% d'adverbes parmi tous les indices et\", round(nb_adv/nb_indicesnonV*100, 2), \"% d'adverbes parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_n/total*100,2), \"% de noms parmi tous les indices et\", round(nb_n/nb_indicesnonV*100, 2), \"% de noms parmi les indices non verbaux\")\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    \n",
    "    print(\"POUR CLAIMS EXTRAITS AVEC SEULEMENT AVEC VERBES, TOUTES PARTIES CONFONDUES\")\n",
    "    \n",
    "    nb_indicesnonV = 0\n",
    "    nb_V = 0\n",
    "    nb_adj = 0\n",
    "    nb_adv = 0\n",
    "    nb_n = 0\n",
    "\n",
    "    for dico in total_claims_v:\n",
    "        for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices_nonV:\n",
    "                    nb_indicesnonV +=1\n",
    "                if word in verbes:\n",
    "                    nb_V += 1\n",
    "                if word in adj : \n",
    "                    nb_adj +=1\n",
    "                if word in adv:\n",
    "                    nb_adv +=1\n",
    "                if word in noms:\n",
    "                    nb_n +=1\n",
    "    total = nb_indicesnonV + nb_V\n",
    "    print(\"\\tIl y a\", total, \"indices au total dans les claims extraits avec seulement les verbes, dont\", nb_V, \"verbes et\", nb_indicesnonV, \"indices non verbaux.\")\n",
    "    print(\"\\t\\tSoit :\", round(nb_indicesnonV/total*100,2), \"% d'indices non verbaux et\", round(nb_V/total*100,2), \"d'indices verbaux.\")\n",
    "    print(\"\\t\\tDétails des indices non verbaux : \", round(nb_adj/total*100,2), \"% d'adjectifs parmi tous les indices et\", round(nb_adj/nb_indicesnonV*100, 2), \"% d'adjectifs parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_adv/total*100,2), \"% d'adverbes parmi tous les indices et\", round(nb_adv/nb_indicesnonV*100, 2), \"% d'adverbes parmi les indices non verbaux\")\n",
    "    print(\"\\t\\t\", round(nb_n/total*100,2), \"% de noms parmi tous les indices et\", round(nb_n/nb_indicesnonV*100, 2), \"% de noms parmi les indices non verbaux\")\n",
    "    print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DICTIONNAIRE POUR VOIR TOP INDICES\"\"\"\n",
    "\n",
    "\"\"\"SUR CLAIMS EXTRAITS AVEC INDICES VERBAUX SEULEMENT\"\"\"\n",
    "partie = [\"abstracts\",\"intros\",\"corps\",\"ccl\"]\n",
    "dico_nbindices_v = {}\n",
    "dico_nbindices = {}\n",
    "\n",
    "for p in partie:\n",
    "    claims = ouvrir_json(\"claims_decoupes_%s_v06-2.json\"%p) #liste de dictionnaires article:claim\n",
    "    for dico in claims:\n",
    "        for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices:\n",
    "                    if word not in dico_nbindices_v:\n",
    "                        dico_nbindices_v[word]=0\n",
    "                    dico_nbindices_v[word]+=1\n",
    "                    \n",
    "    claims = ouvrir_json(\"claims_decoupes_%s_tousindices.json\"%p) #liste de dictionnaires article:claim\n",
    "    for dico in claims:\n",
    "        for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices:\n",
    "                    if word not in dico_nbindices:\n",
    "                        dico_nbindices[word]=0\n",
    "                    dico_nbindices[word]+=1\n",
    "                    \n",
    "    ecrire_json(\"dico_nbindices_v_%s.json\"%p,trier_dic(dico_nbindices_v))\n",
    "    ecrire_json(\"dico_nbindices_%s.json\"%p,trier_dic(dico_nbindices))\n",
    "                    \n",
    "dico_nbindices_v_total = {}\n",
    "dico_nbindices_total = {}\n",
    "for dico in total_claims:\n",
    "    for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices:\n",
    "                    if word not in dico_nbindices_total:\n",
    "                        dico_nbindices_total[word]=0\n",
    "                    dico_nbindices_total[word]+=1\n",
    "                \n",
    "for dico in total_claims_v:\n",
    "    for article, claim in dico.items():\n",
    "            for word in claim.split():\n",
    "                if word in indices:\n",
    "                    if word not in dico_nbindices_v_total:\n",
    "                        dico_nbindices_v_total[word]=0\n",
    "                    dico_nbindices_v_total[word]+=1               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------> abstracts\n",
      "[['can', 12056], ['show', 8272], ['state', 6200], ['find', 2609], ['may', 2194], ['demonstrate', 1929], ['predict', 1886], ['report', 1373], ['support', 1345], ['lead', 1189]] \n",
      "\n",
      "______________________________________________________________________\n",
      "[['can', 13244], ['show', 9551], ['state', 6779], ['find', 3029], ['most', 2971], ['may', 2414], ['best', 2204], ['demonstrate', 2184], ['predict', 2034], ['significantly', 1717]] \n",
      "\n",
      "\n",
      " ******************************************************************************************\n",
      "-------------> intros\n",
      "[['can', 30317], ['show', 15501], ['state', 11604], ['may', 7026], ['find', 6517], ['predict', 3973], ['should', 3360], ['demonstrate', 3322], ['lead', 3193], ['could', 2860]] \n",
      "\n",
      "______________________________________________________________________\n",
      "[['can', 33217], ['show', 17805], ['state', 12715], ['most', 8798], ['may', 7819], ['find', 7560], ['best', 5060], ['predict', 4323], ['possible', 3987], ['should', 3868]] \n",
      "\n",
      "\n",
      " ******************************************************************************************\n",
      "-------------> corps\n",
      "[['can', 151096], ['show', 84036], ['state', 59446], ['find', 41098], ['may', 34295], ['predict', 27680], ['indicate', 20966], ['note', 20029], ['report', 19527], ['should', 19317]] \n",
      "\n",
      "______________________________________________________________________\n",
      "[['can', 165517], ['show', 93954], ['state', 63954], ['most', 48286], ['find', 47873], ['best', 44208], ['may', 38106], ['predict', 30151], ['possible', 24618], ['indicate', 23532]] \n",
      "\n",
      "\n",
      " ******************************************************************************************\n",
      "-------------> ccl\n",
      "[['can', 171234], ['show', 95618], ['state', 66007], ['find', 46501], ['may', 38916], ['predict', 30516], ['indicate', 23474], ['should', 22196], ['note', 22021], ['report', 21671]] \n",
      "\n",
      "______________________________________________________________________\n",
      "[['can', 187704], ['show', 107078], ['state', 71169], ['find', 54228], ['most', 53944], ['best', 50604], ['may', 43298], ['predict', 33271], ['possible', 27935], ['indicate', 26380]] \n",
      "\n",
      "\n",
      " ******************************************************************************************\n",
      "-------------> total\n",
      "[['can', 171234], ['show', 95618], ['state', 66007], ['find', 46501], ['may', 38916], ['predict', 30516], ['indicate', 23474], ['should', 22196], ['note', 22021], ['report', 21671]] \n",
      "\n",
      "______________________________________________________________________\n",
      "[['can', 187704], ['show', 107078], ['state', 71169], ['find', 54228], ['most', 53944], ['best', 50604], ['may', 43298], ['predict', 33271], ['possible', 27935], ['indicate', 26380]] \n",
      "\n",
      "\n",
      " ******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "partie = [\"abstracts\",\"intros\",\"corps\",\"ccl\",\"total\"]\n",
    "liste_top10v = []\n",
    "liste_top10all = []\n",
    "\n",
    "for p in partie:\n",
    "    print(\"------------->\",p)\n",
    "    top10v = ouvrir_json(\"dico_nbindices_v_%s.json\"%p)[:10]\n",
    "    for el in top10v:\n",
    "        if el[0] not in liste_top10v:\n",
    "            liste_top10v.append(el[0])\n",
    "    print(top10v,\"\\n\")\n",
    "    #print(ouvrir_json(\"dico_nbindices_v_%s.json\"%p)[-10:])\n",
    "    print(\"_\"*70)\n",
    "    top10all = ouvrir_json(\"dico_nbindices_%s.json\"%p)[:10]\n",
    "    for el in top10all:\n",
    "        if el[0] not in liste_top10all:\n",
    "            liste_top10all.append(el[0])\n",
    "    print(ouvrir_json(\"dico_nbindices_%s.json\"%p)[:10],\"\\n\")\n",
    "    #print(ouvrir_json(\"dico_nbindices_v_%s.json\"%p)[-10:])\n",
    "    print(\"\\n\",\"*\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mélange des top 10 des indices verbaux : ( 14  éléments) ['can', 'show', 'state', 'find', 'may', 'demonstrate', 'predict', 'report', 'support', 'lead', 'should', 'could', 'indicate', 'note']\n",
      "Mélange des top 10 de tous les indices : ( 13  éléments) ['can', 'show', 'state', 'find', 'most', 'may', 'best', 'demonstrate', 'predict', 'significantly', 'possible', 'should', 'indicate']\n",
      "\n",
      "\n",
      "Intersection :  ['can', 'show', 'state', 'find', 'may', 'demonstrate', 'predict', 'should', 'indicate']\n",
      "Différence (seulement dans indices verbaux):  ['report', 'support', 'lead', 'could', 'note']\n",
      "\t(seulement dans tous indices) :  ['most', 'best', 'significantly', 'possible']\n"
     ]
    }
   ],
   "source": [
    "print(\"Mélange des top 10 des indices verbaux : (\", len(liste_top10v), \" éléments)\", liste_top10v)\n",
    "print(\"Mélange des top 10 de tous les indices : (\", len(liste_top10all), \" éléments)\", liste_top10all)\n",
    "print(\"\\n\")\n",
    "print(\"Intersection : \",[value for value in liste_top10v if value in liste_top10all])\n",
    "print(\"Différence (seulement dans indices verbaux): \",[value for value in liste_top10v if value not in liste_top10all])\n",
    "print(\"\\t(seulement dans tous indices) : \",[value for value in liste_top10all if value not in liste_top10v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"idée de harmonic combinations = ngrammes autour des claims \n",
    "(seulement ceux qui contiennent un autre indice de la grande liste totale ?)\"\"\"\n",
    "\n",
    "partie = [\"abstracts\",\"intros\",\"corps\",\"ccl\"]\n",
    "liste_claims = []\n",
    "\n",
    "for p in partie:\n",
    "    claims = ouvrir_json(\"claims_decoupes_%s_v3.json\"%p)\n",
    "    for dico in claims:\n",
    "        for art, claim in dico.items():\n",
    "            liste_claims.append(claim)\n",
    "        \n",
    "ecrire_json(\"liste_tousclaimspaslem.json\",liste_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_ngrammes = {}\n",
    "for claim in liste_claims:\n",
    "    i = 0\n",
    "    for w in claim.split():\n",
    "        if w in verbes:\n",
    "            if w not in dico_ngrammes:\n",
    "                dico_ngrammes[w]=[]\n",
    "            if i > 0 and i < (len(claim.split())-1):\n",
    "                dico_ngrammes[w].append([claim.split()[i-1],claim.split()[i], claim.split()[i+1]])\n",
    "            elif i ==0 and i < (len(claim.split())-1):\n",
    "                dico_ngrammes[w].append([claim.split()[i],claim.split()[i+1]])\n",
    "            elif i > len(claim.split()):\n",
    "                dico_ngrammes[w].append([claim.split()[i-1], claim.split()[i]])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionnaire de dictionnaires type {indice_v : {co-occu:nb_occu}}\n",
    "dico_ngrammes = {}\n",
    "for claim in liste_claims:\n",
    "    i = 0\n",
    "    for w in claim.split():\n",
    "        if w in verbes:\n",
    "            if w not in dico_ngrammes:\n",
    "                dico_ngrammes[w]={}\n",
    "            if i > 0 and i < (len(claim.split())-1):\n",
    "                if claim.split()[i-1] not in dico_ngrammes[w]:\n",
    "                    dico_ngrammes[w][claim.split()[i-1]] = 0\n",
    "                dico_ngrammes[w][claim.split()[i-1]]+=1\n",
    "                if claim.split()[i+1] not in dico_ngrammes[w]:\n",
    "                    dico_ngrammes[w][claim.split()[i+1]] = 0\n",
    "                dico_ngrammes[w][claim.split()[i+1]]+=1\n",
    "            elif i ==0 and i < (len(claim.split())-1):\n",
    "                if claim.split()[i+1] not in dico_ngrammes[w]:\n",
    "                    dico_ngrammes[w][claim.split()[i+1]] = 0\n",
    "                dico_ngrammes[w][claim.split()[i+1]]+=1\n",
    "            elif i > len(claim.split()):\n",
    "                if claim.split()[i-1] not in dico_ngrammes[w]:\n",
    "                    dico_ngrammes[w][claim.split()[i-1]] = 0\n",
    "                dico_ngrammes[w][claim.split()[i-1]]+=1\n",
    "        i+=1\n",
    "        \n",
    "#print(dico_ngrammes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= could =======================\n",
      "\t [['be', 7374], ['we', 2299], ['not', 1198], ['that', 1111], ['which', 973], ['it', 848], ['also', 708], ['this', 638], ['one', 594], [',', 590]]\n",
      "\n",
      "========================= may =======================\n",
      "\t [['be', 11977], ['not', 3912], ['it', 2244], ['which', 2188], ['have', 1942], ['we', 1420], ['this', 1416], ['that', 1297], ['and', 1141], ['also', 1098]]\n",
      "\n",
      "========================= report =======================\n",
      "\t [['we', 3455], ['the', 3119], ['and', 1045], ['result', 863], [')', 799], [',', 789], ['also', 733], ['on', 483], ['that', 443], ['a', 440]]\n",
      "\n",
      "========================= find =======================\n",
      "\t [['to', 8080], ['we', 6022], ['that', 5848], ['the', 5275], ['a', 2378], ['can', 1336], ['and', 1169], ['it', 664], ['not', 662], ['an', 657]]\n",
      "\n",
      "========================= suggest =======================\n",
      "\t [['that', 2528], ['result', 754], ['we', 520], ['to', 391], ['a', 310], [')', 278], ['and', 242], [',', 200], ['the', 187], ['may', 180]]\n",
      "\n",
      "========================= show =======================\n",
      "\t [['that', 25709], ['the', 14027], ['we', 8530], ['result', 4950], ['1', 3760], ['2', 3321], [')', 2961], ['3', 2804], ['how', 2689], ['a', 2610]]\n",
      "\n",
      "========================= appear =======================\n",
      "\t [['in', 4253], ['to', 1753], ['that', 1273], ['not', 1046], ['can', 498], ['may', 483], ['a', 363], ['they', 346], ['at', 302], ['only', 281]]\n",
      "\n",
      "========================= can =======================\n",
      "\t [['be', 65876], ['we', 26470], ['not', 11916], ['that', 8081], ['it', 6971], ['which', 6773], ['model', 6021], ['also', 4410], ['see', 4290], ['and', 4053]]\n",
      "\n",
      "========================= observe =======================\n",
      "\t [['that', 4129], ['we', 3899], ['can', 940], ['a', 544], ['the', 510], ['also', 441], ['to', 338], ['not', 214], ['and', 198], [',', 174]]\n",
      "\n",
      "========================= demonstrate =======================\n",
      "\t [['that', 2960], ['we', 1702], ['the', 1694], ['to', 918], ['result', 698], ['and', 471], ['how', 259], ['experiment', 244], ['also', 220], ['a', 150]]\n",
      "\n",
      "========================= state =======================\n",
      "\t [['of', 6990], ['hidden', 4726], ['the', 4427], [',', 4059], ['and', 1901], ['a', 1886], ['(', 1877], ['in', 1512], ['that', 1497], ['to', 1401]]\n",
      "\n",
      "========================= support =======================\n",
      "\t [['the', 1896], ['to', 1475], ['vector', 1397], ['of', 788], [',', 728], ['a', 680], ['for', 626], ['and', 493], ['that', 383], ['our', 346]]\n",
      "\n",
      "========================= indicate =======================\n",
      "\t [['that', 2730], ['the', 1492], ['to', 1376], ['result', 721], ['a', 434], ['may', 341], ['which', 287], ['whether', 245], [')', 202], ['can', 201]]\n",
      "\n",
      "========================= predict =======================\n",
      "\t [['to', 6404], ['the', 3869], ['can', 755], ['a', 713], ['we', 423], ['whether', 385], ['and', 366], ['that', 262], [',', 245], ['not', 208]]\n",
      "\n",
      "========================= note =======================\n",
      "\t [['that', 14507], ['we', 1949], [',', 1242], ['to', 827], ['also', 629], [')', 590], ['the', 588], ['de-', 445], ['(', 376], ['should', 240]]\n",
      "\n",
      "========================= lead =======================\n",
      "\t [['to', 10533], ['can', 1263], ['may', 825], ['which', 595], ['this', 564], ['that', 405], ['and', 392], ['the', 350], [',', 349], ['not', 337]]\n",
      "\n",
      "========================= believe =======================\n",
      "\t [['we', 3543], ['that', 2728], ['to', 446], ['the', 353], ['this', 342], [',', 275], ['(', 260], ['i', 218], ['it', 180], ['?', 156]]\n",
      "\n",
      "========================= might =======================\n",
      "\t [['be', 3913], ['not', 900], ['it', 812], ['we', 715], ['one', 634], ['that', 583], ['which', 566], ['have', 493], ['this', 464], [',', 425]]\n",
      "\n",
      "========================= favor =======================\n",
      "\t [['of', 348], ['in', 347], ['to', 193], ['the', 153], ['deny', 65], ['a', 56], ['that', 51], ['should', 46], ['model', 42], [',', 32]]\n",
      "\n",
      "========================= assume =======================\n",
      "\t [['that', 4475], ['we', 3960], ['the', 694], ['a', 516], ['to', 416], ['not', 292], ['can', 246], [',', 234], ['also', 181], ['they', 179]]\n",
      "\n",
      "========================= should =======================\n",
      "\t [['be', 10808], ['it', 2029], ['not', 1778], ['we', 1666], ['have', 981], ['and', 854], ['model', 600], ['that', 548], ['they', 532], ['also', 511]]\n",
      "\n",
      "========================= discover =======================\n",
      "\t [['to', 1072], ['the', 278], ['can', 247], ['that', 150], ['we', 132], ['and', 114], ['new', 89], [',', 82], ['more', 77], ['automatically', 72]]\n",
      "\n",
      "========================= analyze =======================\n",
      "\t [['the', 1578], ['to', 1126], ['we', 946], ['and', 398], ['further', 131], ['how', 115], ['also', 96], ['a', 96], ['can', 84], ['our', 66]]\n",
      "\n",
      "========================= confirm =======================\n",
      "\t [['that', 477], ['to', 310], ['the', 294], ['result', 213], [',', 128], ['we', 111], ['our', 108], ['this', 107], ['and', 71], ['can', 58]]\n",
      "\n",
      "========================= reveal =======================\n",
      "\t [['that', 318], ['the', 256], ['to', 231], ['can', 134], ['result', 81], ['experiment', 57], [',', 55], ['may', 50], ['not', 43], ['a', 41]]\n",
      "\n",
      "========================= conclude =======================\n",
      "\t [['that', 1342], ['we', 935], ['can', 422], ['to', 318], ['and', 198], ['the', 185], ['with', 166], ['in', 154], [',', 84], ['this', 73]]\n",
      "\n",
      "========================= examine =======================\n",
      "\t [['the', 1232], ['we', 898], ['to', 860], ['how', 164], ['whether', 163], ['and', 162], ['also', 100], ['this', 72], ['can', 65], ['a', 65]]\n",
      "\n",
      "========================= comment =======================\n",
      "\t [['and', 839], ['the', 833], [',', 757], ['on', 525], ['of', 426], ['a', 392], ['in', 345], ['for', 268], ['(', 257], ['to', 224]]\n",
      "\n",
      "========================= seem =======================\n",
      "\t [['to', 1549], ['not', 470], ['may', 341], ['might', 174], ['that', 160], ['would', 134], ['they', 81], [',', 80], ['like', 70], ['a', 57]]\n",
      "\n",
      "========================= must =======================\n",
      "\t [['be', 5830], ['we', 1134], ['it', 807], ['have', 760], ['that', 383], ['system', 370], ['also', 341], ['model', 330], ['not', 298], [')', 288]]\n",
      "\n",
      "========================= infer =======================\n",
      "\t [['to', 1903], ['the', 1137], ['that', 547], ['can', 517], ['a', 220], ['we', 174], ['and', 148], ['it', 87], ['from', 84], ['not', 55]]\n",
      "\n",
      "========================= prove =======================\n",
      "\t [['im-', 1005], ['the', 689], ['that', 471], ['to', 443], ['we', 181], ['can', 123], [',', 112], ['useful', 109], ['you', 96], ['may', 86]]\n",
      "\n",
      "========================= claim =======================\n",
      "\t [['the', 1318], [',', 1211], ['that', 1191], ['a', 554], ['and', 518], ['of', 491], ['in', 314], ['(', 267], ['is', 253], ['to', 244]]\n",
      "\n",
      "========================= think =======================\n",
      "\t [['we', 758], ['i', 758], ['that', 582], ['of', 556], ['it', 317], ['to', 266], ['you', 254], ['can', 241], [',', 233], ['the', 223]]\n",
      "\n",
      "========================= explain =======================\n",
      "\t [['the', 899], ['to', 682], ['we', 439], ['how', 321], [',', 314], ['why', 302], ['can', 204], ['and', 128], ['may', 127], ['this', 126]]\n",
      "\n",
      "========================= assert =======================\n",
      "\t [['(', 201], [',', 97], ['that', 62], ['to', 48], ['the', 27], ['can', 25], ['a', 23], ['?', 19], ['might', 18], ['feature', 12]]\n",
      "\n",
      "========================= remark =======================\n",
      "\t [['that', 88], ['we', 63], ['her', 61], ['on', 59], [',', 49], ['and', 44], ['concluding', 37], ['in', 32], [':', 31], ['a', 23]]\n",
      "\n",
      "========================= convince =======================\n",
      "\t [['to', 44], ['the', 16], ['him', 16], [\"n't\", 15], ['would', 12], ['most', 12], ['some', 8], ['could', 8], ['other', 7], [',', 6]]\n",
      "\n",
      "========================= admit =======================\n",
      "\t [[',', 66], ['that', 42], ['to', 36], ['a', 24], ['we', 21], ['not', 21], ['example', 13], ['multiple', 12], ['deny', 12], ['confess', 12]]\n",
      "\n",
      "========================= intend =======================\n",
      "\t [['to', 526], ['we', 364], ['not', 52], ['also', 39], ['(', 15], ['?', 14], ['this', 12], ['further', 11], ['they', 8], ['t', 7]]\n",
      "\n",
      "========================= dare =======================\n",
      "\t [['rule', 14], ['a', 12], [',', 9], ['?', 8], ['to', 6], ['company', 6], ['you', 5], [')', 5], ['(', 5], ['the', 4]]\n",
      "\n",
      "========================= succeed =======================\n",
      "\t [['in', 123], ['to', 112], ['@', 74], ['on', 49], [',', 41], ['at', 32], ['can', 29], ['2', 24], ['1', 24], ['not', 23]]\n",
      "\n",
      "========================= disclose =======================\n",
      "\t [['to', 17], ['the', 10], ['not', 9], [',', 8], ['it', 7], ['how', 5], ['y', 4], ['x', 4], ['and', 4], ['a', 4]]\n",
      "\n",
      "========================= declare =======================\n",
      "\t [['to', 33], ['the', 22], ['and', 16], [',', 16], ['we', 15], ['n', 13], ['can', 11], ['that', 10], ['nihilistically', 8], ['a', 8]]\n"
     ]
    }
   ],
   "source": [
    "dico_ngrammes_trie = {}\n",
    "for indice, dico in dico_ngrammes.items():\n",
    "    dico_ngrammes_trie[indice] = trier_dic(dico)\n",
    "    print(\"\\n=========================\",indice, \"=======================\")\n",
    "    print(\"\\t\",trier_dic(dico)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecrire_json(\"dico_ngrammes_trie.json\",dico_ngrammes_trie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prove\n",
      "['can', 'may', 'could']\n",
      "======================\n",
      "\n",
      "could\n",
      "['lead', 'find', 'possibly', 'indicate', 'explain', 'prove', 'predict', 'observe']\n",
      "======================\n",
      "\n",
      "may\n",
      "['lead', 'appear', 'seem', 'indicate', 'find', 'suggest', 'may', 'explain', 'prove', 'comment', 'assume', 'state', 'think']\n",
      "======================\n",
      "\n",
      "lead\n",
      "['can', 'may', 'could', 'might', 'should']\n",
      "======================\n",
      "\n",
      "report\n",
      "['best', 'state', 'can']\n",
      "======================\n",
      "\n",
      "indicate\n",
      "['may', 'can', 'might', 'clearly', 'could']\n",
      "======================\n",
      "\n",
      "find\n",
      "['can', 'may', 'could', 'evidence', 'support', 'significant', 'must', 'might', 'suggest', 'should']\n",
      "======================\n",
      "\n",
      "suggest\n",
      "['may', 'suggest', 'find', 'evidence', 'can']\n",
      "======================\n",
      "\n",
      "show\n",
      "['significant', 'can', 'clearly', 'state', 'evidence']\n",
      "======================\n",
      "\n",
      "appear\n",
      "['may', 'can', 'must', 'should', 'might']\n",
      "======================\n",
      "\n",
      "confirm\n",
      "['can']\n",
      "======================\n",
      "\n",
      "can\n",
      "['find', 'lead', 'observe', 'predict', 'significantly', 'infer', 'appear', 'state', 'conclude', 'show', 'assume', 'discover', 'support', 'think', 'greatly', 'explain', 'indicate', 'indeed', 'clearly', 'reveal', 'prove', 'can', 'best', 'analyze', 'claim', 'comment', 'report', 'evidence', 'examine', 'suggest', 'guarantee', 'confirm', 'possibly']\n",
      "======================\n",
      "\n",
      "observe\n",
      "['can', 'state', 'significant', 'clearly', 'could']\n",
      "======================\n",
      "\n",
      "demonstrate\n",
      "['clearly', 'state']\n",
      "======================\n",
      "\n",
      "state\n",
      "['can', 'state', 'show', 'report', 'possible', 'most', 'best', 'may', 'observe', 'certain', 'demonstrate']\n",
      "======================\n",
      "\n",
      "support\n",
      "['can', 'evidence', 'support', 'claim', 'find']\n",
      "======================\n",
      "\n",
      "predict\n",
      "['can', 'should', 'must', 'could']\n",
      "======================\n",
      "\n",
      "note\n",
      "['should']\n",
      "======================\n",
      "\n",
      "seem\n",
      "['may', 'might']\n",
      "======================\n",
      "\n",
      "examine\n",
      "['can']\n",
      "======================\n",
      "\n",
      "might\n",
      "['lead', 'seem', 'indicate', 'appear', 'find', 'think']\n",
      "======================\n",
      "\n",
      "analyze\n",
      "['can']\n",
      "======================\n",
      "\n",
      "assume\n",
      "['can', 'may']\n",
      "======================\n",
      "\n",
      "should\n",
      "['note', 'appear', 'lead', 'predict', 'find']\n",
      "======================\n",
      "\n",
      "discover\n",
      "['can']\n",
      "======================\n",
      "\n",
      "reveal\n",
      "['can']\n",
      "======================\n",
      "\n",
      "conclude\n",
      "['can', 'remark']\n",
      "======================\n",
      "\n",
      "think\n",
      "['can', 'might', 'may']\n",
      "======================\n",
      "\n",
      "comment\n",
      "['can', 'may']\n",
      "======================\n",
      "\n",
      "must\n",
      "['appear', 'find', 'predict']\n",
      "======================\n",
      "\n",
      "explain\n",
      "['can', 'may', 'best', 'could']\n",
      "======================\n",
      "\n",
      "infer\n",
      "['can']\n",
      "======================\n",
      "\n",
      "claim\n",
      "['support', 'can']\n",
      "======================\n",
      "\n",
      "remark\n",
      "['conclude']\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Garder seulement les co-occurrents qui font partie des autres indices\"\"\"\n",
    "dico_ngrammes_trie = ouvrir_json(\"dico_ngrammes_trie.json\")\n",
    "dico_ngrammes_ind = {}\n",
    "liste_cooccu = []\n",
    "for verbe, lol in dico_ngrammes_trie.items():\n",
    "    for w in lol:\n",
    "        if w[0] in indices and w[1]>50:\n",
    "            if verbe not in dico_ngrammes_ind :\n",
    "                dico_ngrammes_ind[verbe] = []\n",
    "            dico_ngrammes_ind[verbe].append(w[0])\n",
    "\n",
    "for w, l in dico_ngrammes_ind.items():\n",
    "    print(w)\n",
    "    print(l)\n",
    "    print(\"======================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
